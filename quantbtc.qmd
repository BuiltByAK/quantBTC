---
title: "kdakd"
format: html
editor: visual
---

[Company Overview](https://rpubs.com/Aftikhar/PulsarPeak_Capital_Investment)

# [Investment Strategy: Relative Value Volatility Capture (RVVC)](https://rpubs.com/Aftikhar/crypto_quant_strategy)

If you want to see the full RVVC mental model, click on the link highlighted above.

\
\

Systematic risk and idiosyncratic risks of crypto:

Systematic risks:

1.  Regulatory uncertainty (we cannot control it neither quantitatively measure it)
2.  Macroeconomic conditions: Interst rate hikes, inflation, recession can create fear which reduces risk appetite of investing. We need to get our hands on as many of these as possible.
3.  Technological risks: Vulnerabilites in blockchain infrastructure, attacks or protocol failtures
4.  Market Sentiment and herd behavior: majority of crypto investors are retail, between the ages of 18 - 35. They get most of their investment decisions from social media, panic (fear and greed) and impulsive reaction to news is the biggest reason for volatility associated to this asset class.

Idiosyncratic risk :

1.  Project failture,

2.  smart contract vulnerabilities (bugs expliots that can lead to hacks) causes users to lose confidence in the project,

3.  leadership/developer decisions can make or break a project, tokenomics and supply issues (mismanagement of token supply, inflation).

    These idiosyncratic risks are not alwyse priced in becuase of information asymmetry (investors dont understand it or it is not public information)

Possible things that can impact the price of crypto (specially BTC)

1.  Consumer confidence and traditional market indices: lets correlate most important indices with cryptos
2.  Energy consumption

### ETH_BTC two regimes

```{r}
library(quantmod)
library(magrittr)
library(dplyr)
library(ggplot2)
library(plotly)
library(mixtools)
library(ggplot2)
library(dplyr)
library(scales)

```

The entire ETH_BTC two regime is summarized in two functions

1.  Data retrieval
2.  Creating the chart

```{r, Ratio_function}


get_simple_crypto_ratio <- function(ticker1, ticker2) {
  
    suppressPackageStartupMessages({
    library(quantmod)
    library(xts)
  })
    # --- 1. Fetch Data ---
    # Attempt to fetch data for ticker1
    data1 <- tryCatch({
        getSymbols(ticker1, src = "yahoo", auto.assign = FALSE, warnings = FALSE)
    }, error = function(e) {
        message("Error fetching data for ", ticker1, ": ", e$message)
        return(NULL) # Return NULL if fetching failed
    })

    # Attempt to fetch data for ticker2
    data2 <- tryCatch({
        getSymbols(ticker2, src = "yahoo", auto.assign = FALSE, warnings = FALSE)
    }, error = function(e) {
        message("Error fetching data for ", ticker2, ": ", e$message)
        return(NULL) # Return NULL if fetching failed
    })

    # Check if fetching failed for either ticker
    if (is.null(data1) || is.null(data2)) {
        message("Could not proceed due to data fetching errors.")
        return(invisible(NULL)) # Return NULL invisibly (without printing it)
    }

    # --- 2. Extract Adjusted Prices ---
    # quantmod::Ad extracts the Adjusted closing price column
    adj_price1 <- Ad(data1)
    adj_price2 <- Ad(data2)

    # --- 3. Merge Data ---
    # Use base R merge for xts objects, keeping only dates where both have data
    merged_data <- merge(adj_price1, adj_price2, join = "inner")

    # Check if merge resulted in any common data
     if (nrow(merged_data) == 0) {
         message("No common trading dates found for the selected period.")
         return(invisible(NULL))
     }

    # --- 4. Calculate Ratio ---
    # Get the column names after merge (they often become TICKER.Adjusted)
    col1_name <- names(merged_data)[1]
    col2_name <- names(merged_data)[2]

    # Calculate ratio: Price of Ticker 2 / Price of Ticker 1
    # Avoid division by zero or NA denominators
    valid_rows <- !is.na(merged_data[, col1_name]) & merged_data[, col1_name] != 0
    ratio <- rep(NA, nrow(merged_data)) # Initialize ratio vector with NA
    ratio[valid_rows] <- merged_data[valid_rows, col2_name] / merged_data[valid_rows, col1_name]


    # --- 5. Format Output ---
    # Create a standard data frame for the result
    result_df <- data.frame(
        date = index(merged_data),   # Get dates from the merged xts index
        ratio_value = coredata(ratio) # Get the numeric ratio values
    )

    # Create a dynamic name for the ratio column (e.g., eth_btc_ratio)
    base1 <- tolower(strsplit(ticker1, "-")[[1]][1])
    base2 <- tolower(strsplit(ticker2, "-")[[1]][1])
    ratio_col_name <- paste0(base2, "_", base1, "_ratio")
    names(result_df) <- c("date", ratio_col_name) # Rename columns

    # Remove rows where the ratio calculation resulted in NA
    result_df <- na.omit(result_df)

    # Check if result is empty after NA removal
    if(nrow(result_df) == 0) {
        message("Ratio calculation resulted in zero valid rows.")
        return(invisible(NULL))
    }

    # Return the final data frame
    return(result_df)
}
```

```{r, Gini_lamp_analyze_crypto_ratio}
# Define the extended analysis function
Gini_lamp_analyze_crypto_ratio <- function(data,upper_threshold = 1,
  lower_threshold = -0.8) {
  # --- 1. Load Required Packages ---
  suppressPackageStartupMessages({
    library(ggplot2)
    library(dplyr)
    library(rlang)
    library(mixtools)
    library(patchwork)
    library(stats) # For qnorm in stat_qq
  })

  # --- 2. Input Validation and Dynamic Name Extraction ---
  if (!is.data.frame(data)) {
      stop("Input 'data' must be a data frame.")
  }
  if (!"date" %in% names(data)) {
      stop("Input data frame must contain a 'date' column.")
  }
  ratio_col_name <- setdiff(names(data), "date")
  if (length(ratio_col_name) != 1) {
      stop("Input data frame must have exactly one column besides 'date'. Found: ",
           paste(ratio_col_name, collapse=", "))
  }
  ratio_col_name <- ratio_col_name[1]
  parts <- strsplit(ratio_col_name, "_")[[1]]
    # Adjust index for ticker1 if necessary (e.g., if parts are just 'eth', 'btc', 'ratio')
    ticker1_index <- max(1, length(parts) - 1) # Handle short names, default to 2nd last
  if (length(parts) < 2 || parts[length(parts)] != "ratio") { # Need at least ticker2_ticker1_ratio
       stop("Ratio column name must be in the format 'ticker2_ticker1_ratio'. Found: '", ratio_col_name, "'")
  }
  ticker2_name <- toupper(parts[1])
  ticker1_name <- toupper(parts[ticker1_index])
  pair_name <- paste0(ticker2_name, "/", ticker1_name)
  data <- data %>% dplyr::rename(ratio = !!sym(ratio_col_name))

  # --- 3. Clean Data ---
  clean_data <- data %>%
    filter(!is.na(ratio), is.finite(ratio), ratio != 0)
  if (nrow(clean_data) < 20) {
       stop("Insufficient valid data points (found ", nrow(clean_data), ", need >= 20) after cleaning for model fitting.")
   }

  # --- 4. Fit Gaussian Mixture Model (GMM) ---
  clean_data$log_ratio <- log(clean_data$ratio) # Calculate log_ratio once
  mix_model <- tryCatch({
      normalmixEM(clean_data$log_ratio, k = 2, maxit = 1000, epsilon = 1e-06)
  }, error = function(e) {
      message("Error fitting Gaussian Mixture Model: ", e$message)
      return(NULL)
  })
  if (is.null(mix_model)) {
      stop("Failed to fit Gaussian Mixture Model. Check data distribution or model parameters.")
  }

  # --- 5. Regime Classification and Z-Score Calculation ---
  clean_data$regime <- ifelse(mix_model$posterior[, 1] > 0.5, 1, 2)
  regime_params <- data.frame(
    regime = c(1, 2), mu = mix_model$mu, sigma = mix_model$sigma
  )
  clean_data <- clean_data %>%
    left_join(regime_params, by = "regime") %>%
    mutate(z_score = (log_ratio - mu) / sigma)

  # --- 6. Generate Trading Signals (Dynamically Labeled) ---
  clean_data <- clean_data %>%
    mutate(
      signal = case_when(
        z_score > upper_threshold ~ paste("Short", pair_name, "(overvalued)"),
        z_score < lower_threshold ~ paste("Long", pair_name, "(undervalued)"),
        TRUE ~ "Hold"
      )
    )

  # --- 7. Create Plots ---

  # 7a. Original Signal/Z-Score Plot (Combined)
  plot_ratio <- ggplot(clean_data, aes(x = date)) +
    geom_line(aes(y = ratio, color = as.factor(regime)), linewidth = 0.8) +
    geom_point(data = filter(clean_data, signal != "Hold"),
               aes(y = ratio, shape = signal, color = as.factor(regime)),
               size = 2.5, alpha = 0.8) + # Slightly smaller points
    scale_color_manual(values = c("1" = "#FF6B6B", "2" = "#4ECDC4"), name="Regime") +
    scale_shape_discrete(name = "Signal") +
    labs(title = paste(pair_name, "Ratio with Regimes and Trading Signals"),
         y = "Ratio", x = "Date") +
    theme_minimal() + theme(legend.position = "bottom")
  plot_zscore <- ggplot(clean_data, aes(x = date, y = z_score)) +
    geom_line(color = "steelblue") +
    geom_hline(yintercept = c(lower_threshold, upper_threshold),
               linetype = "dashed", color = "gray40") +
    labs(title = paste("Regime-Specific Z-Score with Thresholds for", pair_name),
         y = "Z-Score", x = "Date") +
    theme_minimal()
  signal_plots_combined <- plot_ratio / plot_zscore +
    plot_layout(heights = c(2, 1))

  # 7b. New Simple Ratio Line Plot
  simple_ratio_plot <- ggplot(clean_data, aes(x = date, y = ratio)) +
    geom_line(color = "blue") +
    labs(title = paste("Simple Time Series of", pair_name, "Ratio"),
         y = "Ratio", x = "Date") +
    theme_minimal()

  # 7c. New Histogram + Density Plot
  histogram_plot <- ggplot(clean_data, aes(x = ratio)) +
    geom_histogram(aes(y = after_stat(density)), bins = 50, fill = "lightblue", color = "black", alpha = 0.7) +
    geom_density(color = "red", linewidth = 1) +
    labs(title = paste("Histogram and Density of", pair_name, "Ratio"),
         x = paste(pair_name, "Ratio"), y = "Density") +
    theme_minimal()

  # 7d. New QQ Plot (using ggplot) for log(ratio)
  qq_plot <- ggplot(clean_data, aes(sample = log_ratio)) + # Use pre-calculated log_ratio
       stat_qq(distribution = stats::qnorm, size=1, alpha=0.6) + # Add size/alpha
       stat_qq_line(distribution = stats::qnorm, color = "red", linetype = "dashed", linewidth=1) +
       labs(title = paste("Normal Q-Q Plot of log(", pair_name, " Ratio)"),
            x = "Theoretical Normal Quantiles", y = "Sample Quantiles (Log Scale)") +
       theme_minimal()

  # --- 8. Return Results ---
  # Return a list containing data, parameters, model object, and all plots
  return(list(
    data_with_signals = clean_data,
    model_parameters = regime_params,
    model_object = plot(mix_model, which = 2),  # Return the model object
    signal_plots_combined = signal_plots_combined, # Original combined plot
    simple_ratio_plot = simple_ratio_plot,     # New plot 1
    histogram_plot = histogram_plot,           # New plot 2
    qq_plot = qq_plot                          # New plot 3
  ))
}

```

```{r}


getSymbols(c("BTC-USD", "ETH-USD"), src = "yahoo", auto.assign = TRUE)
btcp <- data.frame(data=index(`BTC-USD`), coredata(`BTC-USD`)) %>% transmute(date = data, BTC_price = BTC.USD.Adjusted, BTC_volume = BTC.USD.Volume)

ethp <- data.frame(data=index(`ETH-USD`), coredata(`ETH-USD`)) %>% transmute(date = data, ETH_price = ETH.USD.Adjusted, ETH_volume = ETH.USD.Volume)

eth_btc <- inner_join(btcp, ethp, by = "date") %>% transmute(date, ratio = ETH_price/BTC_price) %>% na.omit()

any(is.na(eth_btc$ratio) | is.infinite(eth_btc$ratio) | eth_btc$ratio == 0)
which(is.na(eth_btc$ratio) | is.infinite(eth_btc$ratio) | eth_btc$ratio == 0)

graph_ratio <- ggplot(eth_btc, aes(x = ratio)) +
  geom_histogram(aes(y = ..density..), bins = 150, fill = "lightblue", color = "black") +
  geom_density(color = "red", size = 1) +
  labs(title = "Histogram of ETH/BTC Price Ratio",
       x = "ETH/BTC Ratio", y = "Density")

simple_ratio <- ggplot(eth_btc, aes(x=date, y=ratio))+geom_line()


simple_ratio
graph_ratio
```

Above we see the ratio, and the distribution of the observation. It looks like camel's back with two likely normal distribution. Now lets test for normality.\
\
Now, lets test for normality. The dark line is the observed data and the red line is the expected or theoretical line of a normal distribution. S\
Since the observation does not follow the theoretical line and there is deviation (since the quantiles of our data does not follow the QQline) we can conclude that our data is not normally distributed.

```{r}
qqnorm(log(eth_btc$ratio), main = "QQ Plot of log(ETH/BTC) Ratio")
qqline(log(eth_btc$ratio), col = "red", lwd = 2)
```

```{r}
mix_model <- normalmixEM(log(eth_btc$ratio), k = 2)
summary(mix_model)
plot(mix_model, which = 2)
```

\
Given that it was looking like a bactrian camel's back I wonder if it has two normal distribution within the same data. Each representing a regime. And it seems we are right.

We Used a Gaussian mixture model (from mixtools) to identify two regimes in the log-transformed ETH/BTC ratio. And assigned regimes based on posterior probabilities. We did not use k-mean distribution because it puts a hard clustering label on each data point, whereas GMM model assigns a softer clustering labels and tells how probable it is for a data point to be part of a particular cluster. Data points can have mix memberships. Since our two camel data clusters (as seen in the graph ratio above) merges in the middle GMM is a more suitable option.

**Why GMM Works for ETH/BTC Ratio as compared to Markov Regime-switching model?**

#### **Ratio-Specific Dynamics**

-   The ETH/BTC ratio inherently oscillates between "ETH outperforming BTC" and "BTC outperforming ETH," creating two dominant regimes.

-   GMM captures these scenarios by modeling the ratio’s distribution as a mixture of two Gaussians, each representing a regime (e.g., "ETH dominance" vs. "BTC dominance").

#### **Regime Summary Interpretation**

Your model identifies **two distinct regimes** for the log-transformed ETH/BTC ratio:

1.  **Regime 1 (49.2% probability)**

    -   Mean (`μ₁`): **-3.499** (log ratio)

    -   Volatility (`σ₁`): **0.278**

    -   Implied ETH/BTC ratio: `exp(-3.499)` ≈ **0.030 BTC per ETH**

    -   *Interpretation*: A "low ETH valuation" regime where ETH is relatively cheap compared to BTC.

2.  **Regime 2 (50.8% probability)**

    -   Mean (`μ₂`): **-2.719** (log ratio)

    -   Volatility (`σ₂`): **0.155**

    -   Implied ETH/BTC ratio: `exp(-2.719)` ≈ **0.066 BTC per ETH**

    -   *Interpretation*: A "high ETH valuation" regime where ETH is relatively expensive compared to BTC.

        **Regime Assignment**

First, classify historical data into regimes using posterior probabilities from `mix_model$posterior`:

```{r}
# Assign regimes (prob > 0.5) The first column of the posterior probability matrix from the GMM, which represents the probability that each observation belongs to Regime 1
eth_btc$regime <- ifelse(mix_model$posterior[,1] > 0.5, 1, 2)

eth_btc <- eth_btc %>%
  mutate(
    z_score = case_when(
      regime == 1 ~ (log(ratio) - (-3.499)) / 0.278,
      regime == 2 ~ (log(ratio) - (-2.719)) / 0.155
    )
  )

upper_mean_reversion_threshold <- 1.5
lower_mean_reversion_threshold <- 1.5


eth_btc <- eth_btc %>%
  mutate(
    signal = case_when(
      z_score > upper_mean_reversion_threshold ~ "Short ETH/BTC (overvalued)",
      z_score < lower_mean_reversion_threshold ~ "Long ETH/BTC (undervalued)",
      TRUE ~ "Hold"
    )
  )
```

#### **Regime-Specific Z-Scores**

Calculate how far the current ratio deviates from its regime’s mean (in standard deviations):

```{r}
# Load required libraries

# Plot 1: ETH/BTC Ratio with Regimes and Signals
plot_ratio <- ggplot(eth_btc, aes(x = date)) +
  # Plot ETH/BTC ratio
  geom_line(aes(y = ratio, color = as.factor(regime)), linewidth = 0.8) +
  # Add trading signals
  geom_point(data = subset(eth_btc, signal != "Hold"),
             aes(y = ratio, shape = signal, color = as.factor(regime)),
             size = 3, alpha = 0.8) +
  # Custom colors and labels
  scale_color_manual(values = c("1" = "#FF6B6B", "2" = "#4ECDC4"),
                     name = "Regime") +
  scale_shape_manual(values = c("Short ETH/BTC (overvalued)" = 6,
                                "Long ETH/BTC (undervalued)" = 2)) +
  labs(title = "ETH/BTC Ratio with Regimes and Trading Signals",
       y = "ETH/BTC Ratio",
       x = "Date") +
  theme_minimal() +
  theme(legend.position = "bottom")

# Plot 2: Z-Scores with Thresholds
plot_zscore <- ggplot(eth_btc, aes(x = date)) +
  geom_line(aes(y = z_score, color = "Z-Score"), linewidth = 0.8) +
  geom_hline(yintercept = c(-lower_mean_reversion_threshold, 
                            upper_mean_reversion_threshold),
             linetype = "dashed", color = "gray40") +
  annotate("text", x = min(eth_btc$date), 
           y = upper_mean_reversion_threshold + 0.1,
           label = "Overvalued Threshold", hjust = 0, color = "gray40") +
  annotate("text", x = min(eth_btc$date),
           y = -lower_mean_reversion_threshold - 0.1,
           label = "Undervalued Threshold", hjust = 0, color = "gray40") +
  labs(title = "Z-Score with Mean Reversion Thresholds",
       y = "Z-Score",
       x = "Date") +
  theme_minimal() +
  theme(legend.position = "none")

# Combine both plots
library(patchwork)
combined_plot <- plot_ratio / plot_zscore + 
  plot_layout(heights = c(2, 1))

print(combined_plot)
```

Now that we have two regimes, for each regime we have a different statistical summary. And I used those to calculate the Z score of data within that regime. As a result we have the following data. Regime 2 is when ETH/BTC ratio is high compared to Regime 1. It means that in regime 2 ETH has higher value relative to BTC and in regime 1 its the opposite.

BTC, ETH, XRP, BNB, SOL, DOGE, ADA, TRX, STETH, WBTC, TON, LINK, LEO, AVAX, XLM

```{r}
# Load necessary libraries
library(httr)
library(jsonlite)
library(dplyr)
library(lubridate)
library(readr)

# Define function to fetch each metric
get_metric <- function(endpoint) {
  url <- paste0("https://blockchain.info/q/", endpoint)
  response <- GET(url)
  value <- as.numeric(content(response, "text", encoding = "UTF-8"))
  return(value)
}

# Pull metrics from Blockchain.com API
timestamp <- Sys.time()

block_height <- get_metric("getblockcount")
hash_rate <- get_metric("hashrate")              # GH/s
difficulty <- get_metric("getdifficulty")
market_cap <- get_metric("marketcap") / 1e9      # Convert to billions USD
total_btc <- get_metric("totalbc") / 1e8         # BTC in circulation
unconfirmed_tx <- get_metric("unconfirmedcount")
tx_count_24h <- get_metric("24hrtransactioncount")

# Create a data frame with this snapshot
snapshot <- data.frame(
  timestamp = timestamp,
  block_height = block_height,
  hash_rate_GHs = hash_rate,
  difficulty = difficulty,
  market_cap_BUSD = market_cap,
  total_btc = total_btc,
  unconfirmed_tx = unconfirmed_tx,
  tx_count_24h = tx_count_24h
)

# View it
print(snapshot)

# Load existing data if available
file_path <- "btc_network_stats.csv"
if (file.exists(file_path)) {
  existing_data <- read_csv(file_path)
  updated_data <- bind_rows(existing_data, snapshot)
} else {
  updated_data <- snapshot
}

# Save updated data
write_csv(updated_data, file_path)

```

```{r}
##devtools::install_github("coinmetrics/api-client-r")
#library(coinmetrics)
#No SOL, no SELTH, no ton, no leo, no avax, no SUI, no WSTETH, no USDS, no SHIB, no HBAR


library(coinmetrics)
Sys.setenv()


btc_data <- get_asset_metrics(
  assets = c("btc", "eth", "xrp", "bnb", "doge", "ada", "trx", "wbtc", "link", "ltc", "xlm", "inj"),
  metrics = "PriceUSD",
  start_time = "2013-01-01",
  end_time = Sys.Date()
)

all_symbols_cm
```

# Fear and greed index

```{r, Aftikhar_code}
library(httr)
library(jsonlite)
library(dplyr)

# Fetch Fear & Greed Index data
fg_data <- fromJSON("https://api.alternative.me/fng/?limit=5000")

# Convert to dataframe and process timestamps
fg_df <- fg_data$data %>%
  mutate(
    date = as.Date(as.POSIXct(as.numeric(timestamp))))


# Plot Fear & Greed Index over time
library(ggplot2)

ggplot(fg_df, aes(x = as.Date(date), y = as.numeric(value))) +
  geom_line(color = "#FF6B6B") +
  labs(title = "Crypto Fear & Greed Index", x = "Date", y = "Index Value") +
  theme_minimal()


library(quantmod)
getSymbols("BTC-USD", src = "yahoo", auto.assign = TRUE)

btc_price <- data.frame(date = index(`BTC-USD`), coredata(`BTC-USD`)) %>% select((date), BTC.USD.Adjusted) %>% rename(price_adj = BTC.USD.Adjusted) 

GnF_BTC <- fg_df %>% 
  left_join(
    btc_price,
    by = "date"
  ) %>%
  arrange(date) %>% select(date,value, price_adj, value_classification) %>% mutate(value = as.numeric(value))



library(ggplot2)
library(patchwork)
p1 <- GnF_BTC %>% ggplot(aes(x=date)) + 
  geom_line(aes(y=as.numeric(value))) 

p2 <- GnF_BTC %>% ggplot(aes(x=date, y = price_adj)) + geom_line()

(p1 / p2)




# Load necessary libraries
library(zoo)
library(ggplot2)

# Define your rolling window size
window_size <- 30

# Compute the rolling correlation between 'value' and 'price_adj'
rolling_corr <- rollapply(
  data = GnF_BTC[, c("value", "price_adj")],
  width = window_size,
  FUN = function(x) cor(x[, "value"], x[, "price_adj"], use = "complete.obs"),
  by.column = FALSE,
  fill = NA,
  align = "right"
)

# Add the rolling correlation to your data frame
GnF_BTC$rolling_corr <- as.numeric(rolling_corr)

# Plot the rolling correlation over time
ggplot(GnF_BTC, aes(x = date, y = rolling_corr)) +
  geom_line(color = "steelblue") +
  labs(title = "30-Day Rolling Correlation between Value and Price_adj",
       x = "Date",
       y = "Rolling Correlation") +
  theme_minimal()

```

# **Test10: (look at this one)**

```{r}
# --- 0. Setup: Install and Load Libraries ---
# ... (libraries remain the same) ...
library(tidyverse); library(lmtest); library(car); library(tseries); library(pracma)
library(lubridate); library(httr); library(jsonlite); library(coinmetrics); library(slider)
library(PerformanceAnalytics); library(gridExtra); library(doParallel); library(foreach); library(scales) ; library(crypto2)

# --- 1. Parameters ---
# Data & Timeframe
N_TOP_COINS <- 100
HISTORY_YEARS <- 6
BACKTEST_YEARS <- 2
START_DATE <- Sys.Date() - years(HISTORY_YEARS)
END_DATE <- Sys.Date()
BACKTEST_START_DATE <- END_DATE - years(BACKTEST_YEARS)
TRAINING_END_DATE <- BACKTEST_START_DATE - days(1)

# Filtering
STABLECOINS <- c("USDT", "USDC", "BUSD", "DAI", "TUSD", "USDP", "GUSD", "PAXG", "XAUT")

# --- Explicit List for Assets NOT Supported by CoinMetrics API ---
# Add symbols (lowercase) known to cause issues with the CoinMetrics API fetch here
CM_UNSUPPORTED_ASSETS <- c("sol", "steth", "ton", "leo", "avax", "sui", "wsteth", "usds", "pi", "weth", "usde", "bsc-usd", "hype", "weeth", "wbt", "susds", "cbtc", "susde", "buidl", "lbtc", "kas", "pol", "s", "ftn", "arb", "ip", "solvbtc", "rseth", "weth", "move", "bnsol", "wld", "dexe", "bonk", "sei", "usdt0", "reth", "usd0", "bera", "usdc.e", "flr", "solvbtc.bbn", "pyusd", "wbnb",
                           "om", "inj") # <<< Added om, inj
# ---

# CoinMetrics API Key - Set as environment variable CM_API_KEY
# The R client primarily uses the environment variable.
CM_API_KEY <- Sys.getenv("CM_API_KEY")
if (CM_API_KEY == "") {
  warning("CoinMetrics API Key (CM_API_KEY) is blank. Using free tier access - rate limits and metric availability will be restricted.", immediate. = TRUE)
} else {
  cat("Attempting to use CoinMetrics API Key found in environment variable CM_API_KEY.\n")
}

# Analysis Thresholds
VIF_THRESHOLD <- 5
ADF_P_VALUE_THRESHOLD <- 0.05
HURST_THRESHOLD <- 0.5

# Trading Strategy Parameters (Initial - Will be Optimized)
INITIAL_ROLLING_WINDOW <- 30
INITIAL_ZSCORE_ENTRY <- 1.5
INITIAL_ZSCORE_EXIT <- 0.5
SD_OFFSET <- 1e-9

# Position Sizing Parameters (Initial)
INITIAL_MAX_POSITION_SCALAR <- 2.0
INITIAL_SCALING_FACTOR <- 0.5

# Regime Filter Parameters
REGIME_FILTER_ENABLED <- TRUE
REGIME_VOL_WINDOW <- 60
REGIME_ADR_WINDOW <- 30
REGIME_VOL_PERCENTILE <- 0.75
REGIME_ADR_PERCENTILE <- 0.25

# Optimization Parameters
OPTIMIZE_PARAMETERS <- TRUE
OPTIMIZATION_METRIC <- "Sharpe" # ("Sharpe", "Calmar")
STARTING_BALANCE <- 500000

# Parallel Processing Setup
N_CORES <- detectCores() - 1
if (N_CORES < 1) N_CORES <- 1

# Cache Parameters
CACHE_DIR <- "data_cache"
MAX_CACHE_AGE_DAYS <- 1
FORCE_REFRESH <- FALSE
if (!dir.exists(CACHE_DIR)) { dir.create(CACHE_DIR, showWarnings = FALSE, recursive = TRUE); cat("Cache directory created:", file.path(getwd(), CACHE_DIR), "\n") }

# --- Moved Function Definition: calculate_safe_metrics ---
calculate_safe_metrics <- function(returns_xts, trade_data, scale = 252, Rf = 0) {
    metrics <- list( AnnReturn = NA_real_, AnnStdDev = NA_real_, Sharpe = NA_real_, MaxDD = NA_real_, Calmar = NA_real_, WinPerc = NA_real_, PctInMarket= NA_real_, CumReturn = NA_real_ )
    if (is.null(returns_xts) || nrow(returns_xts) < 20) {
        # cat(" Warning: Not enough returns data (<20) to calculate metrics reliably.\n") # Reduced verbosity
        tryCatch({ metrics$CumReturn <- as.numeric(PerformanceAnalytics::Return.cumulative(returns_xts, geometric=FALSE)) }, error = function(e) {})
        return(metrics)
    }
    sd_val <- sd(coredata(returns_xts), na.rm = TRUE); # cat("  Std Dev Check:", sd_val, "\n") # Debug SD value
    tryCatch({ metrics$MaxDD <- as.numeric(PerformanceAnalytics::maxDrawdown(returns_xts)) }, error = function(e) {cat(" Error MaxDD:", e$message, "\n")})
    tryCatch({ tbl <- PerformanceAnalytics::table.AnnualizedReturns(returns_xts, scale = scale, geometric = FALSE); metrics$AnnReturn <- as.numeric(tbl[1, 1]); metrics$AnnStdDev <- as.numeric(tbl[2, 1]) }, error = function(e) {cat(" Error Ann Ret/Stdev:", e$message, "\n")})
    tryCatch({ metrics$CumReturn <- as.numeric(PerformanceAnalytics::Return.cumulative(returns_xts, geometric=FALSE)) }, error = function(e) {cat(" Error CumReturn:", e$message, "\n")})

    # Calculate trade-based metrics if trade_data is valid and aligns
    if (!is.null(trade_data) && "position" %in% names(trade_data) && nrow(trade_data) == nrow(returns_xts)){
         positions <- trade_data$position[!is.na(trade_data$position)]
         returns_coredata <- coredata(returns_xts)
         if(length(positions) == length(returns_coredata)) {
              returns_in_market <- returns_coredata[positions != 0]
              if(length(returns_in_market) > 0) metrics$WinPerc <- mean(returns_in_market > 0, na.rm=TRUE) else metrics$WinPerc <- NA_real_
              metrics$PctInMarket <- mean(positions != 0, na.rm=TRUE)
         } else {
              # cat(" Warning: Length mismatch returns/positions. Cannot calculate Win%/PctInMarket.\n") # Reduced verbosity
              metrics$WinPerc <- NA_real_; metrics$PctInMarket <- NA_real_
         }
    } else if (!is.null(trade_data)) { cat(" Warning: trade_data issue for Win%/PctInMarket.\n") }

    # Calculate metrics sensitive to standard deviation
    if (!is.na(sd_val) && sd_val > SD_OFFSET) {
        tryCatch({ shp <- PerformanceAnalytics::SharpeRatio.annualized(returns_xts, Rf = Rf, scale = scale, geometric = FALSE); metrics$Sharpe <- as.numeric(shp[1,]) }, error = function(e) {cat(" Error Sharpe:", e$message, "\n")})
        tryCatch({ metrics$Calmar <- as.numeric(PerformanceAnalytics::CalmarRatio(returns_xts, scale = scale)) }, error = function(e) {cat(" Error Calmar:", e$message, "\n")})
    } else {
        # cat(" Warning: Zero SD. Sharpe, Calmar set to NA.\n"); # Reduced verbosity
        metrics$Sharpe <- NA_real_
        if(!is.na(metrics$MaxDD) && !is.null(metrics$MaxDD) && metrics$MaxDD != 0 && !is.na(metrics$AnnReturn) && !is.null(metrics$AnnReturn)) {
           tryCatch({ metrics$Calmar <- metrics$AnnReturn / abs(metrics$MaxDD) }, error=function(e){ metrics$Calmar <- NA_real_})
        } else { metrics$Calmar <- NA_real_ }
    }
    return(metrics)
}
# --- END Function Definition ---


# --- 2. Data Acquisition Part 1: Basic Price Data (CryptoCompare via httr) ---
cat("--- Step 2: Acquiring Basic Price Data ---\n")
# --- Caching for CoinGecko Ranking ---
cg_cache_file <- file.path(CACHE_DIR, paste0("coingecko_ranking_cache_N", N_TOP_COINS, ".rds"))
top_coins_df <- NULL
if (!FORCE_REFRESH && file.exists(cg_cache_file)) { cat("Loading CoinGecko ranking from cache:", cg_cache_file, "\n"); top_coins_df <- tryCatch(readRDS(cg_cache_file), error = function(e) { cat(" Error loading CG cache:", e$message, "\n"); NULL }) }
if (is.null(top_coins_df)) {
    cat("Fetching coin list and market caps from CoinGecko...\n"); tryCatch({
        cg_per_page <- N_TOP_COINS + length(STABLECOINS) + 30; if (cg_per_page > 250) cg_per_page <- 250
        cg_url <- "https://api.coingecko.com/api/v3/coins/markets"; cg_params <- list(vs_currency = "usd", order = "market_cap_desc", per_page = cg_per_page, page = 1, sparkline = "false")
        cg_response <- httr::GET(cg_url, query = cg_params); Sys.sleep(2)
        if (httr::status_code(cg_response) == 200) {
            cg_data <- jsonlite::fromJSON(httr::content(cg_response, "text", encoding = "UTF-8")); top_coins_df <- cg_data %>% as_tibble() %>% select(symbol, id, market_cap) %>% mutate(symbol = toupper(symbol)); cat("Successfully fetched", nrow(top_coins_df), "coins from CoinGecko.\n")
            tryCatch(saveRDS(top_coins_df, file = cg_cache_file), error = function(e) { cat(" Error saving CG cache:", e$message, "\n")})
        } else { stop("Failed CoinGecko fetch. Status: ", httr::status_code(cg_response)) }
    }, error = function(e) { cat("Error CoinGecko:", e$message, "\n"); stop("Cannot proceed.") })
}
# --- Filter for initial candidates ---
cat("Filtering for initial prime candidates...\n"); prime_candidates_info <- top_coins_df %>% filter(!symbol %in% STABLECOINS, symbol != "BTC") %>% slice_head(n = N_TOP_COINS - 1)
initial_prime_candidate_symbols <- prime_candidates_info$symbol; btc_symbol <- "BTC"; initial_all_symbols_of_interest <- c(btc_symbol, initial_prime_candidate_symbols)
if (length(initial_prime_candidate_symbols) < (N_TOP_COINS - 10)) { warning("Fetched fewer candidates than expected: ", length(initial_prime_candidate_symbols)) }
cat("Initial", length(initial_prime_candidate_symbols), "candidates identified for basic fetch:", paste(initial_prime_candidate_symbols, collapse=", "), "\n")

# --- Caching for Basic Price Data ---
basic_data_cache_file <- file.path(CACHE_DIR, paste0("basic_price_data_N", N_TOP_COINS, "_", format(START_DATE),"_",format(END_DATE),".rds"))
all_data_list_basic <- list(); cache_valid_basic <- FALSE
if (!FORCE_REFRESH && file.exists(basic_data_cache_file)) {cache_age <- Sys.time() - file.info(basic_data_cache_file)$mtime; if (cache_age < duration(days = MAX_CACHE_AGE_DAYS)) { cat("Loading basic price data from cache:", basic_data_cache_file, "\n"); all_data_list_basic <- tryCatch(readRDS(basic_data_cache_file), error = function(e) { cat(" Error loading basic price cache:", e$message, "\n"); list() }); if(length(all_data_list_basic) > 0) cache_valid_basic <- TRUE else all_data_list_basic <- list() } else { cat("Basic price cache is outdated.\n") }}
if (!cache_valid_basic) {
    cat("Fetching", HISTORY_YEARS, "years historical PRICE data via httr/jsonlite for ~", length(initial_all_symbols_of_interest), "symbols...\n"); not_found_symbols_basic <- c(); base_url_cc <- "https://min-api.cryptocompare.com/data/v2/histoday"
    api_limit_cc <- as.numeric(END_DATE - START_DATE); if(api_limit_cc > 2000) api_limit_cc <- 2000
    Sys.setenv(TZ='UTC')
    for (sym in initial_all_symbols_of_interest) {
        cat("Fetching price data for:", sym, "..."); tryCatch({
            query_params <- list(fsym = sym, tsym = "USD", limit = api_limit_cc, toTs = as.numeric(as.POSIXct(END_DATE)))
            response <- httr::GET(base_url_cc, query = query_params); Sys.sleep(1.5)
            if (httr::status_code(response) == 200) {
                content <- httr::content(response, "text", encoding = "UTF-8"); json_data <- jsonlite::fromJSON(content)
                if (json_data$Response == "Success" && !is.null(json_data$Data$Data) && nrow(json_data$Data$Data) > 0) {
                    df <- json_data$Data$Data %>% as_tibble(); if ("time" %in% names(df) && "close" %in% names(df)) {
                        df_processed <- df %>% mutate(timestamp = lubridate::as_datetime(time, tz = "UTC"), date = as.Date(timestamp), symbol = sym) %>% select(date, symbol, price = close) %>% filter(date >= START_DATE & date <= END_DATE) %>% arrange(date)
                        if(nrow(df_processed) > 0) { all_data_list_basic[[sym]] <- df_processed; cat(" Success.\n") } else { cat(" No data in range. Skipping.\n"); not_found_symbols_basic <- c(not_found_symbols_basic, sym) }
                    } else { cat(" Missing cols. Skipping.\n"); not_found_symbols_basic <- c(not_found_symbols_basic, sym) }
                } else { cat(" API Error:", json_data$Message, ". Skipping.\n"); not_found_symbols_basic <- c(not_found_symbols_basic, sym) }
            } else { cat(" HTTP Error:", httr::status_code(response), ". Skipping.\n"); not_found_symbols_basic <- c(not_found_symbols_basic, sym) }
        }, error = function(e) { cat(" Error:", e$message, ". Skipping.\n"); not_found_symbols_basic <- c(not_found_symbols_basic, sym); Sys.sleep(1.5) })
    }
    if (length(all_data_list_basic) > 0 && ("BTC" %in% names(all_data_list_basic))) { tryCatch(saveRDS(all_data_list_basic, file = basic_data_cache_file), error = function(e) { cat(" Error saving basic cache:", e$message, "\n")}); cat("Saved basic data to cache:", basic_data_cache_file, "\n") } else { cat("WARNING: Failed fetch sufficient basic data. Cache not saved.\n"); if(!("BTC" %in% names(all_data_list_basic))) stop("Failed fetch BTC basic data.") }
}
# --- Update lists based on fetch/load ---
successfully_fetched_basic <- names(all_data_list_basic); initial_prime_candidate_symbols <- intersect(initial_prime_candidate_symbols, successfully_fetched_basic)
if (!("BTC" %in% successfully_fetched_basic)) stop("BTC basic data missing."); if (length(initial_prime_candidate_symbols) == 0) stop("No candidate basic data.")
cat("Using basic price data for BTC and", length(initial_prime_candidate_symbols), "candidates.\n"); all_data_long_basic <- dplyr::bind_rows(all_data_list_basic) %>% arrange(symbol, date)


# --- 3. Basic Data Preparation ---
cat("--- Step 3: Calculating Returns from Basic Data ---\n")
all_data_calculated_basic <- all_data_long_basic %>%
    mutate(price = as.numeric(price)) %>% group_by(symbol) %>% arrange(date) %>%
    mutate(return = log(price) - log(lag(price))) %>%
    ungroup() %>% filter(!is.na(return))


# --- 4. Training Period Analysis (Identify Potential Pairs using Basic Data) ---
cat("--- Step 4: Analyzing Training Period for Pair Identification (", format(START_DATE), "to", format(TRAINING_END_DATE), ") ---\n")
training_data_basic <- all_data_calculated_basic %>% filter(date <= TRAINING_END_DATE)
pairs_trading_analysis_train <- list(); potentially_mean_reverting_pairs <- c(); training_pair_data_list_basic <- list()
for (candidate_symbol in initial_prime_candidate_symbols) {
    cat("Analyzing pair: BTC vs", candidate_symbol, " (Training - Pair ID)\n"); btc_data_train <- training_data_basic %>% filter(symbol == btc_symbol) %>% select(date, btc_price = price, btc_return = return); candidate_data_train <- training_data_basic %>% filter(symbol == candidate_symbol) %>% select(date, candidate_price = price, candidate_return = return); pair_data_train <- inner_join(btc_data_train, candidate_data_train, by = "date") %>% arrange(date)
    if(nrow(pair_data_train) < INITIAL_ROLLING_WINDOW + 60) { cat(" Insufficient overlap. Skipping pair.\n"); next }
    training_pair_data_list_basic[[candidate_symbol]] <- pair_data_train
    pair_data_train_spread <- pair_data_train %>% filter(candidate_price > 0, btc_price > 0) %>% mutate(spread = log(candidate_price) - log(btc_price))
    if(nrow(pair_data_train_spread) > INITIAL_ROLLING_WINDOW) {
        spread_vector_train <- na.omit(pair_data_train_spread$spread); adf_result_train <- tryCatch(tseries::adf.test(spread_vector_train), error = function(e) NULL); adf_p_value_train <- if (!is.null(adf_result_train)) adf_result_train$p.value else NA; hurst_result_train <- tryCatch(pracma::hurstexp(spread_vector_train, d = INITIAL_ROLLING_WINDOW, display=FALSE), error = function(e) NULL); hurst_value_train <- if (!is.null(hurst_result_train)) hurst_result_train$He else NA
        is_mean_reverting_train <- (!is.na(adf_p_value_train) && adf_p_value_train < ADF_P_VALUE_THRESHOLD) || (!is.na(hurst_value_train) && hurst_value_train < HURST_THRESHOLD)
        pairs_trading_analysis_train[[candidate_symbol]] <- list(adf_p_value = adf_p_value_train, hurst_exponent = hurst_value_train, is_potentially_mean_reverting = is_mean_reverting_train)
        cat("  Spread Analysis (Train): ADF p-val:", round(adf_p_value_train, 4), "| Hurst:", round(hurst_value_train, 3), "\n")
        if(is_mean_reverting_train) { cat("  >>> Pair BTC-", candidate_symbol, "identified potentially mean-reverting. <<<\n"); potentially_mean_reverting_pairs <- c(potentially_mean_reverting_pairs, candidate_symbol) }
    } else { cat("  Insufficient spread data for tests.\n") }
    cat(" --- End analysis for", candidate_symbol, " ---\n")
}
cat("--- Training Period Pair Identification Complete ---\n")
cat("Potentially mean-reverting pairs identified:", paste(potentially_mean_reverting_pairs, collapse=", "), "\n")
if (length(potentially_mean_reverting_pairs) == 0) stop("No potentially mean-reverting pairs identified.")


# --- 4.1 Data Acquisition Part 2: Indicator Data (CoinMetrics) ---
cat("\n--- Step 4.1: Acquiring Indicator Data for Potential Pairs from CoinMetrics ---\n")
# --- Filter potential pairs based on CM_UNSUPPORTED_ASSETS list ---
symbols_to_fetch_indicators_cm <- setdiff(tolower(c(btc_symbol, potentially_mean_reverting_pairs)), CM_UNSUPPORTED_ASSETS) # Lowercase for fetch
if(length(symbols_to_fetch_indicators_cm) <= 1 && "btc" %in% symbols_to_fetch_indicators_cm) { cat("WARNING: All potential pairs unsupported by CM. Cannot fetch indicators.\n"); symbols_for_indicators <- character(0)
} else if (!("btc" %in% symbols_to_fetch_indicators_cm)) { cat("WARNING: BTC unsupported by CM? Cannot fetch indicators.\n"); symbols_for_indicators <- character(0)
} else { symbols_for_indicators <- toupper(symbols_to_fetch_indicators_cm) } # UPPERCASE list for internal use
# --- End Filter ---

metrics_indicators_fetch <- c("AdrActCnt", "TxCnt")
indicator_data_long <- NULL

# --- Caching for Indicator Data ---
indicator_cache_file <- file.path(CACHE_DIR, paste0("indicator_data_N", N_TOP_COINS, "_", format(START_DATE),"_",format(END_DATE),".rds"))
cache_valid_indicator <- FALSE
if (!FORCE_REFRESH && file.exists(indicator_cache_file)) {cache_age <- Sys.time() - file.info(indicator_cache_file)$mtime; if (cache_age < duration(days = MAX_CACHE_AGE_DAYS)) { cat("Loading indicator data from cache:", indicator_cache_file, "\n"); indicator_data_long <- tryCatch(readRDS(indicator_cache_file), error = function(e) { cat(" Error loading indicator cache:", e$message, "\n"); NULL }); if(!is.null(indicator_data_long)) cache_valid_indicator <- TRUE else indicator_data_long <- NULL } else { cat("Indicator cache is outdated.\n") }}

if (!cache_valid_indicator) {
    if (length(symbols_to_fetch_indicators_cm) > 0) { # Only fetch if symbols remain
        cat("Fetching indicators for:", paste(symbols_for_indicators, collapse=", "), "\n") # Print UPPERCASE
        cat("Metrics:", paste(metrics_indicators_fetch, collapse=", "), "\n")
        indicator_data_cm <- tryCatch({
            # --- CORRECTED: Removed api_key argument ---
            coinmetrics::get_asset_metrics(
                 assets = symbols_to_fetch_indicators_cm, # Pass lowercase list
                 metrics = metrics_indicators_fetch,
                 start_time = format(START_DATE), end_time = format(END_DATE), frequency = "1d",
                 paging_from = "start"
            )
            # --- END CORRECTION ---
        }, error = function(e) { cat("Error fetching indicator data:", e$message, "\n"); NULL })

        if (!is.null(indicator_data_cm) && nrow(indicator_data_cm) > 0) {
            cat("Processing indicator data...\n")
            indicator_data_long <- indicator_data_cm %>%
  mutate(date = as.Date(time)) %>%
  select(-time) %>%
  mutate(symbol = toupper(asset)) %>%
  select(date, symbol, everything(), -asset) %>%
  rename(
    adr_act_cnt = AdrActCnt,
    tx_cnt = TxCnt
  ) %>%
  mutate(across(-c(date, symbol), ~ suppressWarnings(as.numeric(.)))) %>%
  arrange(symbol, date)
            tryCatch(saveRDS(indicator_data_long, file = indicator_cache_file), error = function(e) { cat(" Error saving indicator cache:", e$message, "\n")}); cat("Saved indicator data to cache:", indicator_cache_file, "\n")
        } else { cat("WARNING: No indicator data fetched from CoinMetrics.\n") }
    } else {
         cat("Skipping CoinMetrics indicator fetch as no supported pairs were identified.\n")
    }
}
# --- Verify fetched indicators & disable regime if needed ---
fetched_indicators <- if(!is.null(indicator_data_long)) setdiff(names(indicator_data_long), c("date", "symbol")) else character(0)
if (length(fetched_indicators) > 0) cat("Indicators available:", paste(fetched_indicators, collapse=", "), "\n") else cat("No indicators available.\n")
if (REGIME_FILTER_ENABLED && (!("adr_act_cnt" %in% fetched_indicators) || !("BTC" %in% symbols_for_indicators) ) ) { # Check if BTC indicators were fetched
   cat("WARNING: Required indicators/BTC data missing for regime filter. Disabling filter.\n"); REGIME_FILTER_ENABLED <- FALSE
}


# --- 4.2 Combine Basic Data with Indicator Data ---
cat("\n--- Step 4.2: Combining Basic and Indicator Data ---\n")
if (!is.null(indicator_data_long)) { all_data_combined <- left_join(all_data_calculated_basic, indicator_data_long, by = c("date", "symbol"))
} else { all_data_combined <- all_data_calculated_basic %>% mutate(adr_act_cnt = NA_real_, tx_cnt=NA_real_); if (REGIME_FILTER_ENABLED) { cat("Disabling Regime filter.\n"); REGIME_FILTER_ENABLED <- FALSE }}


# --- 4.3 Calculate Rolling Indicators & Refine Pairs ---
cat("\n--- Step 4.3: Calculating Rolling Indicators & Refining Pairs ---\n")
all_data_combined <- all_data_combined %>% group_by(symbol) %>% arrange(date) %>% mutate( rolling_vol = slider::slide_dbl(return, ~sd(.x, na.rm = TRUE), .before = REGIME_VOL_WINDOW - 1, .complete = TRUE), adr_act_smooth = slider::slide_dbl(adr_act_cnt, ~mean(.x, na.rm=TRUE), .before = REGIME_ADR_WINDOW - 1, .complete = TRUE), adr_act_mom = adr_act_smooth / lag(adr_act_smooth, REGIME_ADR_WINDOW) - 1 ) %>% ungroup()
pairs_for_backtesting <- c(); training_pair_data_list_combined <- list(); regime_vol_threshold_value <- NA; regime_adr_mom_threshold_value <- NA
if (REGIME_FILTER_ENABLED) {
     training_data_combined <- all_data_combined %>% filter(date <= TRAINING_END_DATE)
     for (sym in potentially_mean_reverting_pairs) {
          # Check if pair has indicator data AND BTC has indicator data
          btc_check <- training_data_combined %>% filter(symbol=="BTC") %>% summarise(vol_ok = sum(!is.na(rolling_vol)) > REGIME_VOL_WINDOW, adr_ok = sum(!is.na(adr_act_mom)) > REGIME_ADR_WINDOW)
          pair_check <- training_data_combined %>% filter(symbol==sym) %>% summarise(adr_present = "adr_act_cnt" %in% names(.)) # Check if adr_act_cnt column exists for this pair
          if(nrow(pair_check) > 0 && pair_check$adr_present && btc_check$vol_ok && btc_check$adr_ok) {
              btc_data_train_comb <- training_data_combined %>% filter(symbol == btc_symbol) %>% select(date, btc_price = price, btc_return = return, rolling_vol, adr_act_mom)
              candidate_data_train_comb <- training_data_combined %>% filter(symbol == sym) %>% select(date, candidate_price = price, candidate_return = return)
              joined_data <- inner_join(btc_data_train_comb, candidate_data_train_comb, by="date") %>% arrange(date)
              if (nrow(joined_data) > INITIAL_ROLLING_WINDOW + 60) { training_pair_data_list_combined[[sym]] <- joined_data; pairs_for_backtesting <- c(pairs_for_backtesting, sym) # Add to list if data sufficient
              } else {cat(" Skipping pair", sym, "- insufficient overlap after joining combined data.\n")}
          } else { cat(" Skipping pair", sym, "- missing required indicator data in training.\n") }
     }
     if (length(pairs_for_backtesting)==0) { cat("WARNING: No pairs remain after indicator check. Disabling Regime Filter.\n"); REGIME_FILTER_ENABLED <- FALSE; pairs_for_backtesting <- potentially_mean_reverting_pairs # Fallback: Use original pairs list
          # Re-populate training data list if falling back
          for (sym in pairs_for_backtesting) { if(sym %in% names(training_pair_data_list_basic)){ training_pair_data_list_combined[[sym]] <- training_pair_data_list_basic[[sym]] } }
     } else { # Proceed with calculating thresholds
          cat("Pairs with indicator data for regime filter:", paste(pairs_for_backtesting, collapse=", "), "\n"); cat("Calculating regime thresholds...\n")
          btc_regime_data_train <- training_data_combined %>% filter(symbol == btc_symbol)
          if(nrow(btc_regime_data_train) > max(REGIME_VOL_WINDOW, REGIME_ADR_WINDOW*2)) {
               regime_vol_threshold_value <- quantile(btc_regime_data_train$rolling_vol, probs = REGIME_VOL_PERCENTILE, na.rm = TRUE, type = 8)
               regime_adr_mom_threshold_value <- quantile(btc_regime_data_train$adr_act_mom, probs = REGIME_ADR_PERCENTILE, na.rm = TRUE, type = 8)
               cat(" Regime Thresholds (Training): Vol >", round(regime_vol_threshold_value, 6), " & AdrMom <", round(regime_adr_mom_threshold_value, 4), "\n")
               if(is.na(regime_vol_threshold_value) || is.na(regime_adr_mom_threshold_value)){ cat("WARNING: Threshold calc failed. Disabling filter.\n"); REGIME_FILTER_ENABLED <- FALSE }
          } else { cat("WARNING: Not enough data for thresholds. Disabling filter.\n"); REGIME_FILTER_ENABLED <- FALSE }
     }
} else {
     pairs_for_backtesting <- potentially_mean_reverting_pairs
     for (sym in pairs_for_backtesting) { if(sym %in% names(training_pair_data_list_basic)){ training_pair_data_list_combined[[sym]] <- training_pair_data_list_basic[[sym]] }}
     cat("Regime filter disabled. Using all potential pairs:", paste(pairs_for_backtesting, collapse=", "), "\n")
}
if (length(pairs_for_backtesting) == 0) stop("No pairs available for optimization/backtesting.")


# --- 4.5 Parameter Optimization ---
# (Code unchanged - runs using evaluate_params_on_train & training_pair_data_list_combined)
cat("\n--- Step 4.5: Optimizing Parameters on Training Data ---\n")
# ... (optimization loop) ...
param_grid <- expand.grid( roll_window = seq(20, 40, by = 10), entry_z = seq(1.5, 2.0, by = 0.25), exit_z = seq(0.25, 0.75, by = 0.25), max_scalar = INITIAL_MAX_POSITION_SCALAR, scale_factor = INITIAL_SCALING_FACTOR, stringsAsFactors = FALSE) %>% filter(exit_z < entry_z)
cat("Total parameter combinations to test:", nrow(param_grid), "\n")
if (OPTIMIZE_PARAMETERS) {
    cl <- makeCluster(N_CORES); registerDoParallel(cl); cat("\nStarting parallel optimization across", N_CORES, "cores...\n")
    optimization_results_list <- foreach(i = 1:nrow(param_grid), .packages = c("tidyverse", "slider", "PerformanceAnalytics", "xts"), .combine = 'list', .errorhandling = 'pass') %dopar% {
        current_params <- param_grid[i, ]; pair_metrics <- sapply(pairs_for_backtesting, function(sym) { if (sym %in% names(training_pair_data_list_combined)) { evaluate_params_on_train(sym, training_pair_data_list_combined[[sym]], current_params) } else { NA } })
        valid_metrics <- pair_metrics[!is.na(pair_metrics)]; aggregate_metric <- if(length(valid_metrics) > 0) mean(valid_metrics) else NA; list(params = current_params, aggregate_metric = aggregate_metric, num_valid_pairs = length(valid_metrics))
    }
    stopCluster(cl); cat("\nOptimization loop finished.\n"); valid_results <- Filter(function(x) !inherits(x, "error") && is.list(x) && !is.null(x$aggregate_metric) && is.finite(x$aggregate_metric), optimization_results_list)
    if(length(valid_results) > 0) {
        optimization_results_df <- purrr::map_dfr(valid_results, ~bind_cols(as_tibble(.x$params), tibble(aggregate_metric = .x$aggregate_metric, num_valid_pairs = .x$num_valid_pairs)))
        best_result_row <- optimization_results_df %>% arrange(desc(aggregate_metric)) %>% head(1)
        if(nrow(best_result_row) > 0 && is.finite(best_result_row$aggregate_metric)) {
            best_params <- list( roll_window = best_result_row$roll_window, entry_z = best_result_row$entry_z, exit_z = best_result_row$exit_z, max_scalar = best_result_row$max_scalar, scale_factor = best_result_row$scale_factor)
            cat("Best parameters found based on average training", OPTIMIZATION_METRIC, ":\n"); print(bind_rows(best_params)); cat("Best average metric value:", round(best_result_row$aggregate_metric, 4), "\n")
            ROLLING_WINDOW <- best_params$roll_window; ZSCORE_ENTRY_THRESHOLD <- best_params$entry_z; ZSCORE_EXIT_THRESHOLD <- best_params$exit_z; MAX_POSITION_SCALAR <- best_params$max_scalar; SCALING_FACTOR <- best_params$scale_factor
        } else { cat("WARNING: Opti non-finite best metric. Using INITIAL.\n"); ROLLING_WINDOW <- INITIAL_ROLLING_WINDOW; ZSCORE_ENTRY_THRESHOLD <- INITIAL_ZSCORE_ENTRY; ZSCORE_EXIT_THRESHOLD <- INITIAL_ZSCORE_EXIT; MAX_POSITION_SCALAR <- INITIAL_MAX_POSITION_SCALAR; SCALING_FACTOR <- INITIAL_SCALING_FACTOR }
    } else { cat("WARNING: Optimization failed. Using INITIAL.\n"); ROLLING_WINDOW <- INITIAL_ROLLING_WINDOW; ZSCORE_ENTRY_THRESHOLD <- INITIAL_ZSCORE_ENTRY; ZSCORE_EXIT_THRESHOLD <- INITIAL_ZSCORE_EXIT; MAX_POSITION_SCALAR <- INITIAL_MAX_POSITION_SCALAR; SCALING_FACTOR <- INITIAL_SCALING_FACTOR }
} else { cat("Skipping optimization. Using INITIAL.\n"); ROLLING_WINDOW <- INITIAL_ROLLING_WINDOW; ZSCORE_ENTRY_THRESHOLD <- INITIAL_ZSCORE_ENTRY; ZSCORE_EXIT_THRESHOLD <- INITIAL_ZSCORE_EXIT; MAX_POSITION_SCALAR <- INITIAL_MAX_POSITION_SCALAR; SCALING_FACTOR <- INITIAL_SCALING_FACTOR }


# --- 5. Backtesting Period (using Combined Data & Regime Filter) ---
cat("\n--- Step 5: Backtesting Period (", format(BACKTEST_START_DATE), "to", format(END_DATE), ") ---\n")
cat("Using Parameters: Window=", ROLLING_WINDOW, " EntryZ=", ZSCORE_ENTRY_THRESHOLD, " ExitZ=", ZSCORE_EXIT_THRESHOLD, "\n")
if(REGIME_FILTER_ENABLED) cat("Regime Filter: Enabled (Using calculated thresholds)\n") else cat("Regime Filter: Disabled\n")

# Get combined data including buffer for rolling calcs
backtest_data_full_period <- all_data_combined %>%
    filter(symbol %in% c(btc_symbol, pairs_for_backtesting)) %>%
    filter(date >= BACKTEST_START_DATE - days(max(ROLLING_WINDOW, REGIME_VOL_WINDOW, REGIME_ADR_WINDOW*2)))

# Add regime state for backtest period using TRAINING thresholds
if(REGIME_FILTER_ENABLED) {
    backtest_data_full_period <- backtest_data_full_period %>%
        mutate(
             is_high_vol = rolling_vol > regime_vol_threshold_value,
             is_low_adr_mom = adr_act_mom < regime_adr_mom_threshold_value,
             market_regime = ifelse(!is.na(is_high_vol) & !is.na(is_low_adr_mom) & is_high_vol & is_low_adr_mom, "High Risk", "Normal"),
             market_regime = ifelse(is.na(market_regime), "Normal", market_regime) # Fill NAs
        )
} else {
     backtest_data_full_period <- backtest_data_full_period %>% mutate(market_regime = "Normal") # Dummy column
}

backtest_details <- list() # Store results
for (candidate_symbol in pairs_for_backtesting) { # Use the final list
    cat("Backtesting pair: BTC vs", candidate_symbol, "\n")
    # Filter data for the pair for the full period needed
    btc_data_backtest <- backtest_data_full_period %>% filter(symbol == btc_symbol) %>% select(date, btc_price = price, btc_return = return, market_regime) # Keep regime
    candidate_data_backtest <- backtest_data_full_period %>% filter(symbol == candidate_symbol) %>% select(date, candidate_price = price, candidate_return = return)
    pair_data_backtest <- inner_join(btc_data_backtest, candidate_data_backtest, by = "date") %>% filter(btc_price > 0, candidate_price > 0) %>% arrange(date)

    if(nrow(pair_data_backtest) < ROLLING_WINDOW + 5) { cat(" Insufficient overlap. Skipping.\n"); next }

    # Calculate Spread, Z-Score, Signals, Positions (using regime filter)
    pair_data_signals <- pair_data_backtest %>%
        mutate(
            spread = log(candidate_price) - log(btc_price),
            rolling_mean = slider::slide_dbl(spread, mean, .before = ROLLING_WINDOW - 1, .complete = FALSE, na.rm = TRUE),
            rolling_sd = slider::slide_dbl(spread, sd, .before = ROLLING_WINDOW - 1, .complete = FALSE, na.rm = TRUE),
            rolling_sd = ifelse(is.na(rolling_sd) | rolling_sd < SD_OFFSET, NA, rolling_sd),
            zscore = ifelse(is.na(rolling_sd), NA, (spread - rolling_mean) / rolling_sd)
        ) %>%
        filter(date >= BACKTEST_START_DATE, !is.na(zscore))

     if(nrow(pair_data_signals) < 2) { cat(" Insufficient data post Z-score. Skipping.\n"); next }

     # Apply regime filter logic here
     pair_data_trades <- pair_data_signals %>%
         mutate(
            raw_signal = case_when(zscore > ZSCORE_ENTRY_THRESHOLD ~ -1, zscore < -ZSCORE_ENTRY_THRESHOLD ~ 1, abs(zscore) < ZSCORE_EXIT_THRESHOLD ~ 0, TRUE ~ NA_real_),
            raw_signal = zoo::na.locf(raw_signal, na.rm = FALSE, fromLast=FALSE), raw_signal = ifelse(is.na(raw_signal), 0, raw_signal),
            prev_raw_signal = lag(raw_signal, default = 0),
            # Apply Regime Filter: Prevent *new* entries during High Risk
            current_signal = ifelse(prev_raw_signal == 0 & raw_signal != 0 & market_regime == "High Risk", 0, raw_signal),
            # Position based on previous day's *filtered* signal
            prev_signal = lag(current_signal, default = 0),
            prev_zscore = lag(zscore, default = 0), prev_prev_signal = lag(prev_signal, default=0),
            # Position Sizing (same logic as before)
            size_scalar = case_when( prev_signal == -1 & prev_prev_signal == 0 ~ pmin(1 + SCALING_FACTOR * (prev_zscore - ZSCORE_ENTRY_THRESHOLD), MAX_POSITION_SCALAR),
                                     prev_signal == 1 & prev_prev_signal == 0 ~ pmin(1 + SCALING_FACTOR * (abs(prev_zscore) - ZSCORE_ENTRY_THRESHOLD), MAX_POSITION_SCALAR),
                                     prev_signal != 0 & prev_signal == prev_prev_signal ~ lag(pmax(1.0, case_when( lag(prev_signal, default=0) == -1 & lag(prev_prev_signal, default=0) == 0 ~ pmin(1 + SCALING_FACTOR * (lag(prev_zscore,default=0) - ZSCORE_ENTRY_THRESHOLD), MAX_POSITION_SCALAR), lag(prev_signal, default=0) == 1 & lag(prev_prev_signal, default=0) == 0 ~ pmin(1 + SCALING_FACTOR * (abs(lag(prev_zscore,default=0)) - ZSCORE_ENTRY_THRESHOLD), MAX_POSITION_SCALAR), TRUE ~ 1.0 )), default=1.0),
                                     TRUE ~ 1.0),
            size_scalar = ifelse(prev_signal == 0, 0, pmax(1.0, size_scalar)),
            position = prev_signal * size_scalar
        ) %>% mutate(position = as.numeric(position))

    # Calculate Strategy Returns
    pair_strategy_returns_tibble <- pair_data_trades %>%
        mutate( candidate_return = as.numeric(candidate_return), btc_return = as.numeric(btc_return),
                strategy_return = position * (candidate_return - btc_return),
                strategy_return = ifelse(is.finite(strategy_return), strategy_return, 0),
                symbol = candidate_symbol) %>%
        select(date, symbol, strategy_return)

    backtest_details[[candidate_symbol]] <- list(trade_data = pair_data_trades, returns_data = pair_strategy_returns_tibble)
    cat(" Backtesting calculations complete for", candidate_symbol, "\n")
}


# --- 6. Performance Metrics & Drawdown Calculation (No Omega) ---
# (Code unchanged - Uses the safe metric calculation function)
cat("\n--- Step 6: Calculating Performance Metrics ---\n")
if (length(backtest_details) == 0) stop("No pairs successfully backtested.")
# calculate_safe_metrics function defined earlier
# ... (Aggregate and Individual calculations using calculate_safe_metrics) ...
# --- 6a. Aggregate Performance ---
all_strategy_returns_long <- bind_rows(lapply(backtest_details, `[[`, "returns_data"))
portfolio_daily_returns <- all_strategy_returns_long %>% group_by(date) %>% summarise(portfolio_return = mean(strategy_return, na.rm = TRUE), .groups = 'drop') %>% arrange(date) %>% mutate(portfolio_return = ifelse(is.na(portfolio_return), 0, portfolio_return))
if (nrow(portfolio_daily_returns) > 0) {
    portfolio_returns_xts_agg <- xts::xts(portfolio_daily_returns$portfolio_return, order.by = portfolio_daily_returns$date)
    colnames(portfolio_returns_xts_agg) <- "Aggregate Strategy"
    cat("\n--- AGGREGATE Backtest Performance Metrics ---\n")
    agg_metrics <- calculate_safe_metrics(portfolio_returns_xts_agg, trade_data = NULL)
    cat("Annualized Return:", scales::percent(agg_metrics$AnnReturn, accuracy=0.01), "\n"); cat("Annualized Std Dev:", scales::percent(agg_metrics$AnnStdDev, accuracy=0.01), "\n"); cat("Cumulative Return:", scales::percent(agg_metrics$CumReturn, accuracy=0.01), "\n"); cat("Annualized Sharpe (Rf=0%):", round(agg_metrics$Sharpe, 3), "\n"); cat("Maximum Drawdown:", scales::percent(agg_metrics$MaxDD, accuracy=0.01), "\n"); cat("Calmar Ratio:", round(agg_metrics$Calmar, 3), "\n")
} else { cat("\nError: Aggregate returns empty.\n"); stop("Cannot calculate aggregate metrics.") }
# --- 6b. Individual Pair Performance & Drawdowns ---
cat("\n--- INDIVIDUAL Pair Backtest Performance & Drawdowns ---\n")
individual_metrics_list <- list(); individual_drawdown_tables <- list()
for (candidate_symbol in names(backtest_details)) {
    cat("--- Pair: BTC vs", candidate_symbol, "---\n"); pair_returns_tibble <- backtest_details[[candidate_symbol]]$returns_data; pair_trade_data <- backtest_details[[candidate_symbol]]$trade_data
    if (nrow(pair_returns_tibble) > 1) {
        pair_returns_tibble <- pair_returns_tibble %>% mutate(strategy_return = ifelse(is.na(strategy_return), 0, strategy_return)); pair_returns_xts <- xts::xts(pair_returns_tibble$strategy_return, order.by = pair_returns_tibble$date); colnames(pair_returns_xts) <- candidate_symbol
        pair_metrics <- calculate_safe_metrics(pair_returns_xts, pair_trade_data); individual_metrics_list[[candidate_symbol]] <- pair_metrics
        cat(" Annualized Return:", scales::percent(pair_metrics$AnnReturn, accuracy=0.01), "\n"); cat(" Annualized Std Dev:", scales::percent(pair_metrics$AnnStdDev, accuracy=0.01), "\n"); cat(" Cumulative Return:", scales::percent(pair_metrics$CumReturn, accuracy=0.01), "\n"); cat(" Win % (of active days):", scales::percent(pair_metrics$WinPerc, accuracy=0.1), "\n"); cat(" % Time In Market:", scales::percent(pair_metrics$PctInMarket, accuracy=0.1), "\n"); cat(" Annualized Sharpe (Rf=0%):", round(pair_metrics$Sharpe, 3), "\n"); cat(" Maximum Drawdown:", scales::percent(pair_metrics$MaxDD, accuracy=0.01), "\n"); cat(" Calmar Ratio:", round(pair_metrics$Calmar, 3), "\n")
        dd_table <- tryCatch(PerformanceAnalytics::table.Drawdowns(pair_returns_xts, top=5), error=function(e) NULL)
        if(!is.null(dd_table)) { cat(" Top 5 Drawdowns:\n"); print(dd_table); individual_drawdown_tables[[candidate_symbol]] <- dd_table } else { cat(" Could not calculate drawdown table.\n") }
        cat("\n")
    } else { cat(" Insufficient return data for", candidate_symbol, "\n\n") }
}
# --- 6c. Create Summary Table ---
summary_df <- tryCatch({bind_rows(lapply(individual_metrics_list, function(l) as.data.frame(l)), .id = "Candidate") %>% mutate(Pair = paste("BTC", Candidate, sep="-")) %>% select(Pair, AnnReturn, AnnStdDev, Sharpe, MaxDD, Calmar, WinPerc, PctInMarket, CumReturn) %>% arrange(desc(Sharpe))}, error = function(e) { cat("Error creating summary table:", e$message, "\n"); NULL })
if (!is.null(summary_df)){ cat("\n--- Performance Summary Table ---\n"); print(summary_df, digits=3) }


# --- 7. Plotting (Revised Strategy Plot) ---
# (Code unchanged - plots reflect updated backtest including regime filter effect)
cat("\n--- Step 7: Plotting Results ---\n")
plot_dir <- "strategy_plots"; if (!dir.exists(plot_dir)) dir.create(plot_dir)
cat("Plots will be saved to:", file.path(getwd(), plot_dir), "\n")
agg_plot_file <- file.path(plot_dir, "00_aggregate_performance.png"); png(agg_plot_file, width=800, height=1000); tryCatch({ PerformanceAnalytics::charts.PerformanceSummary(portfolio_returns_xts_agg, main = "Aggregate Strategy Performance", geometric = FALSE)}, error=function(e) plot.new()); dev.off()
btc_prices_backtest <- all_data_calculated_basic %>% filter(symbol == btc_symbol, date >= BACKTEST_START_DATE) %>% select(date, btc_price = price) # Use basic data for price plot
for (candidate_symbol in names(backtest_details)) {
    cat("Generating plots for BTC vs", candidate_symbol, "\n"); pair_plot_data <- backtest_details[[candidate_symbol]]$trade_data; pair_returns_data <- backtest_details[[candidate_symbol]]$returns_data
    # Plot 1: Spread + Z-Score + Entries + Regime Background
    trade_entries <- pair_plot_data %>% filter(abs(position) > SD_OFFSET & abs(lag(position, default = 0)) < SD_OFFSET) %>% mutate(entry_type = ifelse(position > 0, "Long Spread", "Short Spread"))
    plot_spread <- ggplot(pair_plot_data, aes(x = date, y = spread)) + geom_line(color="black") + labs(title = paste("BTC vs", candidate_symbol, ": Log Spread"), x = NULL, y = "Log Spread") + theme_minimal() + theme(plot.title = element_text(size=10))
    plot_zscore <- ggplot(pair_plot_data, aes(x = date, y = zscore)) +
        geom_rect(data = . %>% filter(market_regime == "High Risk"), aes(xmin=date, xmax=lead(date, default=max(date)+days(1)), ymin=-Inf, ymax=Inf), fill="grey80", alpha=0.3, inherit.aes = FALSE) +
        geom_line(color="black") + geom_hline(yintercept = c(ZSCORE_ENTRY_THRESHOLD, -ZSCORE_ENTRY_THRESHOLD), color = "red", linetype = "dashed") + geom_hline(yintercept = c(ZSCORE_EXIT_THRESHOLD, -ZSCORE_EXIT_THRESHOLD), color = "blue", linetype = "dotted") + geom_hline(yintercept = 0, color = "grey") +
        geom_point(data = trade_entries, aes(color = entry_type), size = 2) + scale_color_manual(values = c("Long Spread" = "darkgreen", "Short Spread" = "darkred")) +
        labs(title = paste("Z-Score & Entries (Win:", ROLLING_WINDOW, " Entry:", ZSCORE_ENTRY_THRESHOLD, " Exit:", ZSCORE_EXIT_THRESHOLD, ")"), x = "Date", y = "Z-Score", color = NULL) + theme_minimal() + theme(legend.position = "bottom", plot.title = element_text(size=10))
    pair_plot_file_spread <- file.path(plot_dir, paste0("01_spread_z_", candidate_symbol, ".png"))
    tryCatch({ ggsave(pair_plot_file_spread, gridExtra::grid.arrange(plot_spread, plot_zscore, ncol = 1, heights = c(1, 2)), width=10, height=6); cat(" Spread/Z plot saved:", pair_plot_file_spread, "\n") }, error = function(e){cat(" Could not save spread/z plot:", e$message, "\n")})
    # Plot 2: Strategy Results Plot (Style like example)
    plot_data_strategy <- pair_plot_data %>% select(date, position, market_regime) %>% inner_join(pair_returns_data, by="date") %>% inner_join(btc_prices_backtest, by="date") %>%
        mutate(strategy_return = ifelse(is.na(strategy_return), 0, strategy_return), CumEQ = STARTING_BALANCE * cumprod(1 + strategy_return),
               trade_signal = case_when( sign(position) != 0 & lag(sign(position), default=0) == 0 ~ sign(position), sign(position) == 0 & lag(sign(position), default=0) != 0 ~ -lag(sign(position)), TRUE ~ 0 ),
               pos_start = date, pos_end = lead(date, default = END_DATE + days(1)), position_plot = ifelse(abs(position) < SD_OFFSET, NA, position))
    p_price <- ggplot(plot_data_strategy, aes(x=date, y=btc_price)) + geom_line() + labs(y=NULL, x=NULL) + theme_minimal(base_size = 9) + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank()) + ggtitle(paste("Strategy Results: BTC vs", candidate_symbol)) # Remove y-axis label
    p_trades <- ggplot(plot_data_strategy %>% filter(trade_signal != 0), aes(x=date, y=0)) + geom_point(aes(shape=factor(sign(trade_signal)), color=factor(sign(trade_signal))), size=2.0) + scale_shape_manual(values=c("1"=17, "-1"=17), guide="none") + scale_color_manual(values=c("1"="darkgreen", "-1"="darkred"), guide="none") + labs(y="Trades", x=NULL) + ylim(-1, 1) + theme_minimal(base_size = 9) + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())
    p_pos <- ggplot(plot_data_strategy %>% filter(!is.na(position_plot))) + geom_rect(aes(xmin = pos_start, xmax = pos_end, ymin = 0, ymax = position_plot, fill = factor(sign(position_plot))), alpha=0.8) + geom_hline(yintercept=0) + scale_fill_manual(values=c("1"="blue", "-1"="lightblue"), guide="none") + labs(y="Position", x=NULL) + theme_minimal(base_size = 9) + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank()) + ylim(-MAX_POSITION_SCALAR*1.1, MAX_POSITION_SCALAR*1.1)
    p_cumeq <- ggplot(plot_data_strategy, aes(x=date, y=CumEQ)) + geom_line(color="blue") + labs(y="Equity", x="Date") + theme_minimal(base_size = 9) + scale_y_continuous(labels = scales::comma)
    pair_plot_file_strategy <- file.path(plot_dir, paste0("02_strategy_results_", candidate_symbol, ".png"))
    tryCatch({ ggsave(pair_plot_file_strategy, gridExtra::grid.arrange(p_price, p_trades, p_pos, p_cumeq, ncol=1, heights=c(3, 0.5, 1.5, 2)), width=8, height=6); cat(" Strategy results plot saved:", pair_plot_file_strategy, "\n") }, error=function(e){cat(" Could not save strategy plot:", e$message, "\n")})
}

# --- 8. Notes on Bitcoin Fundamental Value Strategy ---
# (Code unchanged)
cat("\n--- Step 8: Notes on Bitcoin Fundamental Value Strategy --- \n")#...rest of notes

# --- 9. Notes on Dynamic Portfolio Rebalancing ---
# (Code unchanged)
cat("\n--- Step 9: Notes on Dynamic Portfolio Rebalancing ---\n") #...rest of notes

cat("\n--- Analysis, Optimization, Backtesting, and Plotting Finished ---\n")
```
